# Mini Project 1 - CMSC818B Decisioin Making for Robotics

## ICRA 2023 Workshop - ScalableAD
_This workshop presents good literature related to solving challenging problems in Autonomous Driving Systems_
<br>
[ScalableAD website](https://sites.google.com/view/icra2023av)

The ICRA workshop on scalable autonomous driving addresses some of the biggest and complex challenges that are being faced while developing autonomous vehicles. The issue of scalability has been considered from various viewpoints in robotics in this workshop. The viewpoints span from issues in generating rare driving scenarios for training autonomous agents, developing new perception techniques that can fuse multiple sensor information, to connected autonomous vehicles (AVs).

The scalability issue of AVs  is of utmost importance if we wish to deploy them at scale in multiple cities across the globe. As we find more efficient methods for solving different problems faced by AVs, such as generating BEV (Bird’s Eye View) by fusing multiple on-board sensors, our ability to test and enhance such methods should also improve. This is only possible if we consciously push towards more scalable algorithms and techniques that are designed for AVs. By having scalable technologies, we can ensure that the solutions devised are globally optimum and generalize well across different scenarios that the autonomous agent may face while driving.

### Index:
1. [F2BEV: Bird's Eye View Generation from Surround-View Fisheye Camera Images](#topic1)
2. [Scaling AV through Adversarial Scenario Generation and Continual Learning](#topic2)

Demo equation: 
<br/>
![formula](https://render.githubusercontent.com/render/math?math=e^{i \pi} = -1)
<br/>
![formula](https://render.githubusercontent.com/render/math?math= \sqrt{3x-1}+(1+x)^2)

### <a name="topic1">Topic 1: F2BEV: Bird's Eye View Generation from Surround-View Fisheye Camera Images for Automated Driving.</a>

In [1], Samani, et. al. propose a baseline algorithm to generate BEV (Bird’s Eye View) representation constructed from surround-view fisheye cameras. As more and more AVs (Autonomous Vehicles) are deployed, the higher dependency on vision based sensors and ranging sensors is bound to grow exponentially. This higher demand may lead to bottlenecks in sensor supply chains, causing deployment delays and increasing cost of AVs for the users. Using fisheye cameras, fewer cameras are needed to capture the entire surroundings of an AV. Thus, by reducing the number of cameras, hardware requirements and possible points of failure are reduced.

The paper has 2 major contributions in the area of generating BEV. Firstly, they propose the baseline model F2BEV that generates BEV from Fisheye cameras. This method is the first algorithm that works on creating BEV using distortion aware models. The existing models work by undistorting the images from fisheye cameras and then proceeding with traditional methods for BEV generation. By using this novel approach, the authors outperform not only the approaches for BEV generation from fisheye cameras, but also BEV generation from traditional pinhole cameras. The authors also consider single-task and multi-task maps. In single-task maps, a single map (such as just the height map or the semantic segmentation map) is generated by one pass of the network. In multi-task map, both the height and segmentation maps are generated simultaneously. It is found that the performance of single-task and multi-task approaches are similar, while the multi-task approach provides significant performance boost over single-task map generation.

Secondly, the authors have created a dataset - FB-SSEM dataset. This dataset consists of images from four surround-view fisheye cameras, the motion information of the ego vehicle, ground truth BEV semantic segmentation and height map. The dataset consists of 20 sequences of an ego vehicle in different parking lots, where each sequence consists of 1000 temporal samples. The temporal information is necessary for generating accurate BEVs. This dataset attempts to fill the disparity between the size of datasets between BEV maps and F2BEV maps for public use.

In my opinion, this research helps in solving a very important issue: reducing the number of sensors required to perform autonomous driving. A famous quote by Elon Musk says that we won’t need any other sensors once we solve vision. I think this is true because as humans we only have access to vision sensors (our 2 eyes) to perceive threats around us, and we are rather good drivers. Hence, an autonomous agent, whose sole purpose is to drive, should be able to do so with just surround view cameras. This also reduces the potential points of failure and the processing resources required. 

I also believe that the authors provide a good starting point for further research in generating BEV from wide angle cameras. Better performing and more efficient algorithms can certainly be developed from this point on. The dataset developed (SSEB dataset) should be further expanded to incorporate more scenarios and classes of objects (currently only 5 classes are included).

Open challenges: Baseline, hence computational performance needs to be analyzed. For real time applications, the algorithm should be computationally efficient to allow deployment on-board actual AVs. Thus, a study should be conducted that assesses the latency introduced by the proposed algorithm and what potential improvements can be made to make it more efficient. Further, the authors only consider 5 classes for semantic segmentation and only 3 levels in height map generation. This level of granularity may be insufficient for deployment of the algorithm in complex and rich city environments. Thus, a more comprehensive class set can be explored.


### <a name="topic2"></a>Topic 2: Scaling AV through Adversarial Scenario Generation and Continual Learning.
_Talk by: Yuning Chai (Head of AI Research at Cruise)_

Dr. Chai talks about how generating adversarial scenarios using GANs can help in providing additional learning examples for the agent. He addresses how generative AI can be used to provide a scalable technology that can generate good training data. This is essential to help in expanding the categories of scenarios that are available as training data. 

Modern neural networks are composed of billions of parameters that are very data hungry and need large amounts of data (often in terabytes or even petabytes) to generalize well. The talk  proposes a method of multi-pass learning in which we can eliminate the need of storing old data without sacrificing the performance metrics on old data. This helps in solving the scalability issue in continual learning in AI models.

Generative AI paves the way to generate realistic examples in high-dimensional spaces such as RGB images or 3-dimensional paths. The talk makes an important contribution of using generative AI to generate realistic but improbable pedestrian behavior. This has been accomplished by modifying the architecture of the generator of a traditional GAN where a single neural network is used to produce the output. Here, an encoder and a decoder are used to make up the generator network. An additional embedding is generated from the desired distribution and passed to the decoder that generates an output sample (as seen in fig. 1). By using this method, the authors improve the chances of obtaining ‘valid’ samples that will be more suitable candidates for training the underlying neural network.

<p align="center">
  <img src="images/fig1_cruise.png" alt="Encoder Decoder GAN" width="600" />
  <br/>
  <em>Fig 1: Modified GAN architecture</em>
</p>

Another important contribution in the area of continual learning of neural networks has been made. In most approaches, access to old data (not for retraining, but for evaluation) is often required or the approach is not scalable to multiple fine-tuning stages. In the proposed method, the weight updates are made based on only the new data but using the original checkpoint model’s weights as reference. An example can be seen in fig. 2, where the weight updates are calculated by a combination of gradients obtained from the current model and new data and the difference between the current model and check-pointed model. Using this method, the need to store old data is eliminated while ensuring that the model does not ‘forget’ the old data.


<p align="center">
  <img src="images/fig2_cruise.png" alt="PC grad idea" width="600" />
  <br/>
  <em>Fig. 2: The idea of PC grad</em>
</p>

I believe that the presentation fits well in the context of scalable AI. The authors not only introduce an important issue when dealing with scalable autonomous driving systems, but present interesting approaches towards solving it. The idea of generative AI being used to generate training samples in the context of robotics is gaining traction. It is being used in CNNs, path planning, RL-based control systems, and as already mentioned, in autonomous driving systems. This is important because collecting data for robotic systems is often a laborious task and consists of data from multiple sensors. Thus, collecting real-world data for unlikely scenarios may not be feasible for many applications. If generative AI can help in generating realistic data that is well diversified, the time-to-market can be significantly improved while ensuring that the model can generalize to complicated scenarios. However, a quantitative quality-of-sample should be established for applicability of the proposed method in real-world scenarios.

Further, in the context of continual learning, elimination of dependence on large amounts of data is essential in the longer term, however, the talk does go into a lot of detail regarding the performance benefits of PC grad when compared to other approaches. The idea is enticing and I believe that further analysis should be done to conclude the efficacy of the proposed method.

Though Dr. Chai addresses important issues towards scalable autonomous driving, additional research is necessary to measure and ensure the diversity of samples generated. Generative AI is difficult to train and can lead to inaccurate samples that might misguide the learning process. A metric to measure the ‘validity’ of generated samples should be devised which could help in discarding invalid samples. Such a metric would enable researchers to analyze the distribution of output generated by the AI and further tweak the AI to give more evenly distributed samples that constitute a varied set of scenarios.



<ol>
  <li>
    Samani, Ekta U., Feng Tao, Harshavardhan R. Dasari, Sihao Ding, and Ashis G. Banerjee. "F2BEV: Bird's Eye View Generation from Surround-View Fisheye Camera Images for Automated Driving." arXiv preprint arXiv:2303.03651 (2023).
  </li>
  <li>
    Talk 1: Scaling AV Across the US by Dr. Yuning Chai. 
  </li>
</ol>

